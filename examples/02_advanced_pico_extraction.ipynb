{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabfccc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Example 2: Programmatic Usage and Advanced Extraction\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates how to use `evidence-extractor` as a Python library, rather than just a command-line tool.\\n\",\n",
    "    \"\\n\",\n",
    "    \"This is useful for integrating the extraction logic into your own custom analysis workflows.\\n\",\n",
    "    \"\\n\",\n",
    "    \"We will cover:\\n\",\n",
    "    \"1.  Importing and using the core functions programmatically.\\n\",\n",
    "    \"2.  Focusing on specific extractions, like PICO and Quality Scores.\\n\",\n",
    "    \"3.  Directly accessing the structured Pydantic data models.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Setup and Imports\\n\",\n",
    "    \"\\n\",\n",
    "    \"First, we import the necessary functions from our library. We will also need to instantiate the `GeminiClient` as our functions rely on it.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"from pprint import pprint\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import the core functions we want to use\\n\",\n",
    "    \"from evidence_extractor.core.ingest import ingest_pdf\\n\",\n",
    "    \"from evidence_extractor.core.preprocess import extract_text_from_doc, clean_and_consolidate_text\\n\",\n",
    "    \"from evidence_extractor.extraction.pico import extract_pico_elements\\n\",\n",
    "    \"from evidence_extractor.extraction.methods import extract_methods_and_quality\\n\",\n",
    "    \"from evidence_extractor.integration.gemini_client import GeminiClient\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Ensure your GEMINI_API_KEY is set in your .env file\\n\",\n",
    "    \"# The GeminiClient will load it automatically.\\n\",\n",
    "    \"gemini_client = GeminiClient()\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not gemini_client.is_configured():\\n\",\n",
    "    \"    print(\\\"ERROR: Gemini client is not configured. Please check your .env file.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"pdf_path = \\\"../data/raw/sample.pdf\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not os.path.exists(pdf_path):\\n\",\n",
    "    \"    print(f\\\"ERROR: Sample PDF not found at {pdf_path}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Preprocessing the Document\\n\",\n",
    "    \"\\n\",\n",
    "    \"Just like in the main CLI, our first step is to ingest the PDF and extract the cleaned text. This text will be the input for our AI-powered functions.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"document = ingest_pdf(pdf_path)\\n\",\n",
    "    \"pages_text = extract_text_from_doc(document)\\n\",\n",
    "    \"_, cleaned_text = clean_and_consolidate_text(pages_text)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# We'll use a snippet for efficiency, as PICO and Methods are usually in the abstract/intro\\n\",\n",
    "    \"text_snippet = cleaned_text[:8000]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Successfully processed PDF. Text snippet length: {len(text_snippet)} characters.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Extracting PICO Elements\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now we can call the `extract_pico_elements` function directly. It takes the Gemini client and the text snippet as input and returns a Pydantic `PICO` object.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"pico_result = extract_pico_elements(gemini_client, text_snippet)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if pico_result:\\n\",\n",
    "    \"    print(\\\"--- Extracted PICO Elements ---\\\")\\n\",\n",
    "    \"    # We can access the fields of the Pydantic model directly\\n\",\n",
    "    \"    print(f\\\"Population: {pico_result.population}\\\")\\n\",\n",
    "    \"    print(f\\\"Intervention: {pico_result.intervention}\\\")\\n\",\n",
    "    \"    print(f\\\"Comparison: {pico_result.comparison}\\\")\\n\",\n",
    "    \"    print(f\\\"Outcome: {pico_result.outcome}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # The object also contains the default correction metadata\\n\",\n",
    "    \"    print(f\\\"\\\\nValidation Status: {pico_result.correction_metadata.status.value}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Extracting Methodological Quality\\n\",\n",
    "    \"\\n\",\n",
    "    \"Similarly, we can call the `extract_methods_and_quality` function to get a `QualityScore` object.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"quality_result = extract_methods_and_quality(gemini_client, text_snippet)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if quality_result:\\n\",\n",
    "    \"    print(\\\"--- Extracted Quality Score ---\\\")\\n\",\n",
    "    \"    print(f\\\"Score Name: {quality_result.score_name}\\\")\\n\",\n",
    "    \"    print(f\\\"Score Value: {quality_result.score_value}\\\")\\n\",\n",
    "    \"    print(f\\\"Justification: {quality_result.justification}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"By importing functions directly, you can build custom workflows. For example, you could loop over a directory of PDFs, extract only the PICO elements for each one, and save the results directly to a CSV file, bypassing the main `extract` command's full pipeline.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
